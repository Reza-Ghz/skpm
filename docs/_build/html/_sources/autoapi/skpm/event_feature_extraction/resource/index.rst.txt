:py:mod:`skpm.event_feature_extraction.resource`
================================================

.. py:module:: skpm.event_feature_extraction.resource


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   skpm.event_feature_extraction.resource.ResourcePoolExtractor




.. py:class:: ResourcePoolExtractor(threshold=0.7)


   Bases: :py:obj:`sklearn.base.TransformerMixin`, :py:obj:`sklearn.base.BaseEstimator`

   Proposed in [1]. Code adapted from [2].

   TODO: implement other distance metrics.

   .. rubric:: References

   [1] Minseok Song, Wil M.P. van der Aalst. Towards comprehensive support for organizational mining, Decision Support Systems (2008).
   [2] https://github.com/AdaptiveBProcess/GenerativeLSTM

   .. rubric:: Notes

   - distance metrics: (dis)similarity between two vectors (variables). It must
   satisfy the following mathematical properties: d(x,x) = 0, d(x,y) >= 0,
   d(x,y) = d(y,x), d(x,z) <= d(x,y) + d(y,z)
   - correlation coeficients: statistical relationships between vectors (variables)
   that quantify how much they are related.

   The original paper mentions Pearson correlation as a distance metric. For
   academic purposes, it's crucial to grasp the distinction since correlation
   does not satisfy the triangular inequality. Yet, there are instances where
   I think correlation can be informally employed as a 'similarity' measure.
   In the context of organizational mining, I believe statistical relationships
   and similarity ultimately serve the same purpose.

   .. py:method:: get_feature_names_out()


   .. py:method:: fit(X: pandas.DataFrame, y=None)


   .. py:method:: transform(X: pandas.DataFrame, y=None)


   .. py:method:: _validate_data(X: pandas.DataFrame)

      Validate input data and set or check the `n_features_in_` attribute.

      :param X: The input samples.
                If `'no_validation'`, no validation is performed on `X`. This is
                useful for meta-estimator which can delegate input validation to
                their underlying estimator(s). In that case `y` must be passed and
                the only accepted `check_params` are `multi_output` and
                `y_numeric`.
      :type X: {array-like, sparse matrix, dataframe} of shape                 (n_samples, n_features), default='no validation'
      :param y: The targets.

                - If `None`, `check_array` is called on `X`. If the estimator's
                  requires_y tag is True, then an error will be raised.
                - If `'no_validation'`, `check_array` is called on `X` and the
                  estimator's requires_y tag is ignored. This is a default
                  placeholder and is never meant to be explicitly set. In that case
                  `X` must be passed.
                - Otherwise, only `y` with `_check_y` or both `X` and `y` are
                  checked with either `check_array` or `check_X_y` depending on
                  `validate_separately`.
      :type y: array-like of shape (n_samples,), default='no_validation'
      :param reset: Whether to reset the `n_features_in_` attribute.
                    If False, the input will be checked for consistency with data
                    provided when reset was last True.
                    .. note::
                       It is recommended to call reset=True in `fit` and in the first
                       call to `partial_fit`. All other methods that validate `X`
                       should set `reset=False`.
      :type reset: bool, default=True
      :param validate_separately: Only used if y is not None.
                                  If False, call validate_X_y(). Else, it must be a tuple of kwargs
                                  to be used for calling check_array() on X and y respectively.

                                  `estimator=self` is automatically added to these dicts to generate
                                  more informative error message in case of invalid input data.
      :type validate_separately: False or tuple of dicts, default=False
      :param cast_to_ndarray: Cast `X` and `y` to ndarray with checks in `check_params`. If
                              `False`, `X` and `y` are unchanged and only `feature_names_in_` and
                              `n_features_in_` are checked.
      :type cast_to_ndarray: bool, default=True
      :param \*\*check_params: Parameters passed to :func:`sklearn.utils.check_array` or
                               :func:`sklearn.utils.check_X_y`. Ignored if validate_separately
                               is not False.

                               `estimator=self` is automatically added to these params to generate
                               more informative error message in case of invalid input data.
      :type \*\*check_params: kwargs

      :returns: **out** -- The validated input. A tuple is returned if both `X` and `y` are
                validated.
      :rtype: {ndarray, sparse matrix} or tuple of these


   .. py:method:: _check_unknown(input: numpy.ndarray, vocab: numpy.ndarray, name: str)


   .. py:method:: _define_vocabs(unique_labels: numpy.ndarray)



